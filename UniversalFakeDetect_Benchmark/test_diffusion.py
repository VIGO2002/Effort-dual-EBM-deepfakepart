import os
import torch
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.utils.data import DataLoader, ConcatDataset
from sklearn.metrics import average_precision_score, accuracy_score
from models.trainer import Trainer
from options.train_options import TrainOptions
import numpy as np
from tqdm import tqdm

# ================= é…ç½®åŒºåŸŸ =================
# 1. çœŸå›¾åŸºå‡†ï¼šGuided Diffusion å’Œ LDM éƒ½æ˜¯åŸºäº ImageNet çš„
# æ‰€ä»¥å¿…é¡»ä½¿ç”¨ BigGAN çš„çœŸå›¾ (ImageNet) ä½œä¸ºè´Ÿæ ·æœ¬
BASE_REAL_PATH = "/root/autodl-tmp/datasets/CNNDetection/biggan/0_real"

# 2. æ‰©æ•£æ¨¡å‹å‡å›¾æ ¹ç›®å½•
DIFFUSION_ROOT = "/root/autodl-tmp/datasets/Diffusion"

# 3. ä½ çš„ç›®æ ‡ï¼šåŸè®ºæ–‡åœ¨ Guided ä¸Šçš„åˆ†æ•°
BASELINE_GUIDED = 95.39 
# ===========================================

def load_diffusion_vs_imagenet(fake_path, transform):
    """
    åŠ è½½ç­–ç•¥ï¼š
    Real: BigGAN/0_real (ImageNet) -> Label 0
    Fake: æŒ‡å®šçš„æ‰©æ•£æ¨¡å‹æ–‡ä»¶å¤¹ -> Label 1
    """
    try:
        # --- 1. åŠ è½½ Real (ImageNet) ---
        if not os.path.exists(BASE_REAL_PATH):
            print(f"âŒ Error: Real path not found: {BASE_REAL_PATH}")
            return None
        
        # æ‰‹åŠ¨æ„å»º Real Dataset
        real_samples = []
        valid_ext = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')
        for f in os.listdir(BASE_REAL_PATH):
            if f.lower().endswith(valid_ext):
                real_samples.append((os.path.join(BASE_REAL_PATH, f), 0)) # Label 0
        
        # --- 2. åŠ è½½ Fake (Diffusion) ---
        fake_samples = []
        # é€’å½’æ‰«æ fake_path ä¸‹çš„æ‰€æœ‰å›¾ç‰‡
        for root, _, files in os.walk(fake_path):
            for f in files:
                if f.lower().endswith(valid_ext):
                    fake_samples.append((os.path.join(root, f), 1)) # Label 1
        
        if len(fake_samples) == 0:
            print(f"âš ï¸  No images found in {fake_path}")
            return None

        # --- 3. æ‰“å°æ•°æ®é‡å¯¹æ¯” ---
        print(f"   ğŸ“Š Data: {len(real_samples)} Real (ImageNet) vs {len(fake_samples)} Fake (Diffusion)")
        
        # --- 4. ç»„è£… Dataset ---
        # å€Ÿç”¨ ImageFolder çš„ç»“æ„ï¼Œä½†æ›¿æ¢ samples
        # è¿™é‡Œéšä¾¿æŒ‡ä¸€ä¸ªå­˜åœ¨çš„è·¯å¾„åˆå§‹åŒ–å³å¯ï¼Œé‡ç‚¹æ˜¯åé¢çš„ samples è¦†ç›–
        dataset = datasets.ImageFolder(root=os.path.dirname(BASE_REAL_PATH), transform=transform)
        
        # åˆå¹¶æ ·æœ¬
        full_samples = real_samples + fake_samples
        dataset.samples = full_samples
        dataset.targets = [s[1] for s in full_samples]
        
        return dataset

    except Exception as e:
        print(f"âŒ Dataset Error: {e}")
        return None

def run_test(model, dataset_name, root_path, transform):
    fake_path = os.path.join(root_path, dataset_name)
    print(f"\n{'='*10} âš”ï¸  Challenging {dataset_name.upper()} âš”ï¸  {'='*10}")
    
    dataset = load_diffusion_vs_imagenet(fake_path, transform)
    if dataset is None: return None
    
    # Batch size 32 ä¿è¯æ˜¾å­˜å®‰å…¨
    dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)
    
    y_true, y_pred = [], []
    model.model.cuda()
    
    with torch.no_grad():
        for i, data in tqdm(enumerate(dataloader), total=len(dataloader), leave=False):
            model.set_input(data)
            model.test()
            
            # è·å–é¢„æµ‹ç»“æœ
            # å¦‚æœä½ çš„ EBM æœ‰ç‰¹æ®Šçš„è¯„åˆ†æœºåˆ¶ (æ¯”å¦‚ output æ˜¯ energy score)ï¼Œ
            # è¿™é‡Œå¯èƒ½éœ€è¦è°ƒæ•´ã€‚ç›®å‰å‡è®¾ output ä¾ç„¶æ˜¯ logitsã€‚
            pred = model.output
            
            if pred.shape[1] == 1:
                prob = torch.sigmoid(pred).cpu().numpy().flatten()
            else:
                prob = torch.softmax(pred, dim=1)[:, 1].cpu().numpy()
            
            y_true.extend(data[1].cpu().numpy())
            y_pred.extend(prob)

    mAP = average_precision_score(y_true, y_pred)
    acc = accuracy_score(y_true, [1 if p > 0.5 else 0 for p in y_pred])
    
    # ç»“æœåˆ¤å®š
    status = "Fail âŒ"
    if dataset_name == 'guided':
        if mAP * 100 > BASELINE_GUIDED:
            status = "VICTORY! ğŸ† (SOTA)"
        else:
            gap = BASELINE_GUIDED - mAP * 100
            status = f"Lagging by {gap:.2f}%"
            
    print(f"ğŸ¯ Result for {dataset_name}:")
    print(f"   mAP: {mAP:.4f} ({mAP*100:.2f}%) | Acc: {acc:.4f} | {status}")
    return mAP

if __name__ == "__main__":
    # --- 1. åˆå§‹åŒ–æ¨¡å‹ (Epoch 8) ---
    opt = TrainOptions().parse(print_options=False)
    opt.isTrain = False; opt.gpu_ids = [0]; opt.name = 'effort_universal_repro'; opt.checkpoints_dir = './checkpoints'
    opt.arch = 'CLIP:ViT-L/14_svd'; opt.fix_backbone = True; opt.noise_std = 0.02
    
    print("âš¡ï¸ Loading Your Modified Model (Dual-Head EBM)...")
    model = Trainer(opt)
    model.eval()
    
    # åŠ è½½æœ€å¼ºçš„ Epoch 8
    ckpt_path = './checkpoints/effort_universal_repro/model_epoch_3.pth'
    state_dict = torch.load(ckpt_path, map_location='cpu')
    if 'model' in state_dict: state_dict = state_dict['model']
    
    # å…¼å®¹æ€§åŠ è½½
    if hasattr(model.model, "module"): model.model.module.load_state_dict(state_dict, strict=False)
    else: model.model.load_state_dict(state_dict, strict=False)
    print("âœ… Weights loaded! Ready to fight Diffusion.")

    # --- 2. Transform ---
    val_transform = transforms.Compose([
        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))
    ])

    # --- 3. ç›®æ ‡æ•°æ®é›†åˆ—è¡¨ (æ ¹æ®ä½ çš„ ls ç»“æœ) ---
    # é‡ç‚¹å…³æ³¨ guided
    TARGETS = [
        'guided',          # é‡ç‚¹ï¼Target: > 95.39
        'ldm_100',         # Latent Diffusion
        'ldm_200_cfg',     # Classifier Free Guidance
        'glide_100_27',    # GLIDE
        'dalle',           # DALL-E
        'pndm'             # PNDM Sampler
    ]

    results = {}
    print(f"\nğŸ¯ Baseline to beat (Guided): {BASELINE_GUIDED}%")
    
    for d_name in TARGETS:
        score = run_test(model, d_name, DIFFUSION_ROOT, val_transform)
        if score is not None:
            results[d_name] = score

    print(f"\n{'='*20} ğŸ† Final Diffusion Leaderboard ğŸ† {'='*20}")
    for k, v in results.items():
        print(f"{k.ljust(15)}: {v:.4f}")
